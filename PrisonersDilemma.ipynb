{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for the simulation\n",
    "import openai  # OpenAI's API for GPT models\n",
    "import os  # Operating system interfaces, not used directly in this snippet but typically for file paths\n",
    "import re\n",
    "import random  # To introduce randomness in decisions\n",
    "import matplotlib.pyplot as plt  # For plotting the results\n",
    "from langchain.llms import OpenAI  # LangChain wrapper for easier use of OpenAI's language models\n",
    "import csv\n",
    "import time  # Import the time module\n",
    "\n",
    "# Initialize LangChain's Language Learning Models (LLMs) with an OpenAI API key\n",

    "\n",
    "api_key = \"#######################",
    "\n",
    "class Agent:\n",
    "    def __init__(self, name, llm_api_key, strategy_func=None):\n",
    "        self.name = name\n",
    "        self.llm_api_key = llm_api_key\n",
    "        self.strategy_func = strategy_func\n",
    "        self.history = []\n",
    "        self.score = 0\n",
    "\n",
    "    # Ensure decide_action is correctly indented to be part of the Agent class\n",
    "    def decide_action(self):\n",
    "        if self.name == 'Agent A' and self.strategy_func:\n",
    "            opponent_history = [round_result['Agent B'] for round_result in self.history]\n",
    "            return self.strategy_func(opponent_history)\n",
    "            \n",
    "        if self.name == 'Agent B':\n",
    "            opponent_last_action = 'Cooperate' if not self.history else self.history[-1]['Agent A']\n",
    "            #prompt = f\"Given your history in the Prisoner's Dilemma game and that your opponent's last action was '{opponent_last_action}', what would you choose to do? Cooperate or Defect?\"\n",
    "            prompt = f\"You are Agent B in a game of Prisoner's Dilemma.  The history of the game so far is {self.history}. What would you choose to do.  Respond by only using the word 'Cooperate' or 'Defect'.  Then explain your decision\"\n",
    "\n",
    "            # Initialize OpenAI with the provided API key\n",
    "            openai.api_key = self.llm_api_key\n",
    "\n",
    "            try:\n",
    "                # Use the updated method for creating chat completions\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo-0125\", #\"gpt-4-turbo-preview\",  #\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a wise oracle. Please provide guidance.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                decision = \"Unknown\"\n",
    "\n",
    "\n",
    "            llmresp = None\n",
    "\n",
    "            # Search for 'Cooperate' or 'Defect' in the decision text.\n",
    "            match = re.search(r'Cooperate|Defect', response)\n",
    "\n",
    "            if match:\n",
    "                # If a match is found, use it.\n",
    "                llmresp = match.group()\n",
    "            else:\n",
    "                # If no match is found, randomly choose one.\n",
    "                llmresp = random.choice([\"Cooperate\", \"Defect\"])\n",
    "                print(\"Random selection made\")\n",
    "\n",
    "            # Log the results of each LLM action to a file for analysis\n",
    "            with open(\"llm_log.txt\", 'a') as log_file:\n",
    "                log_file.write(f\"{prompt}\\n{response}\\n{llmresp}\\n-----------------------------------------------------------------------\\n\")\n",
    "\n",
    "            # Ensure the response is valid or choose randomly\n",
    "            return llmresp\n",
    "\n",
    "\n",
    "\n",
    "    def update_score(self, other_agent_action):\n",
    "        \"\"\"\n",
    "        Updates the agent's score based on the outcome of the round.\n",
    "        \n",
    "        :param other_agent_action: A string representing the other agent's last action ('Cooperate' or 'Defect').\n",
    "        \"\"\"\n",
    "        # Retrieve this agent's last action\n",
    "        my_last_action = self.history[-1][self.name]\n",
    "        \n",
    "        # Update scores according to the rules of Prisoner's Dilemma\n",
    "        if my_last_action == 'Cooperate':\n",
    "            if other_agent_action == 'Cooperate':\n",
    "                self.score += 3  # Reward for mutual cooperation\n",
    "            else:\n",
    "                self.score += 0  # Penalty for being exploited\n",
    "        else:\n",
    "            if other_agent_action == 'Cooperate':\n",
    "                self.score += 5  # Reward for exploiting the other\n",
    "            else:\n",
    "                self.score += 1  # Small reward for mutual defection\n",
    "\n",
    "def tit_for_tat(opponent_history):\n",
    "    \"\"\"\n",
    "    Implements the 'Tit for Tat' strategy: cooperate on the first move, then replicate the opponent's last move.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Cooperate' if no history; otherwise, the opponent's last action.\n",
    "    \"\"\"\n",
    "    return 'Cooperate' if not opponent_history else opponent_history[-1]\n",
    "\n",
    "def tit_for_two_tats(opponent_history):\n",
    "    \"\"\"\n",
    "    A more forgiving version of Tit for Tat that defects only after the opponent defects twice in a row.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Cooperate' unless the opponent's last two actions were 'Defect'.\n",
    "    \"\"\"\n",
    "    if len(opponent_history) < 2 or opponent_history[-2:] != ['Defect', 'Defect']:\n",
    "        return 'Cooperate'\n",
    "    return 'Defect'\n",
    "\n",
    "def generous_tit_for_tat(opponent_history):\n",
    "    \"\"\"\n",
    "    Similar to Tit for Tat but occasionally cooperates randomly even after the opponent defects.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Cooperate' by default; 'Defect' if the opponent defected last, with a small chance to forgive.\n",
    "    \"\"\"\n",
    "    if not opponent_history or opponent_history[-1] == 'Cooperate' or random.random() < 0.1:\n",
    "        return 'Cooperate'\n",
    "    return 'Defect'\n",
    "\n",
    "def grim_trigger(opponent_history):\n",
    "    \"\"\"\n",
    "    Cooperates until the opponent defects once, after which it always defects.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Cooperate' if no defections; 'Defect' after the first defection.\n",
    "    \"\"\"\n",
    "    return 'Defect' if 'Defect' in opponent_history else 'Cooperate'\n",
    "\n",
    "def pavlov(opponent_history):\n",
    "    \"\"\"\n",
    "    Cooperates if both agents made the same choice in the last round, otherwise defects.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Cooperate' if the last two actions match; otherwise, 'Defect'.\n",
    "    \"\"\"\n",
    "    if len(opponent_history) < 2:\n",
    "        return 'Cooperate'\n",
    "    return 'Cooperate' if opponent_history[-1] == opponent_history[-2] else 'Defect'\n",
    "\n",
    "def adaptive_strategy(opponent_history):\n",
    "    \"\"\"\n",
    "    Adapts its action based on the frequency of cooperation and defection by the opponent.\n",
    "    If the opponent has cooperated more often, it cooperates, aiming to foster mutual cooperation.\n",
    "    If the opponent has defected more frequently, it defects, protecting itself from being exploited.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Cooperate' or 'Defect' based on the adaptive strategy.\n",
    "    \"\"\"\n",
    "    if not opponent_history:\n",
    "        return 'Cooperate'  # Cooperate by default on the first move\n",
    "    cooperate_count = opponent_history.count('Cooperate')\n",
    "    defect_count = len(opponent_history) - cooperate_count\n",
    "    if cooperate_count > defect_count:\n",
    "        return 'Cooperate'  # Foster mutual cooperation\n",
    "    else:\n",
    "        return 'Defect'  # Protect from exploitation\n",
    "\n",
    "def suspicious_tit_for_tat(opponent_history):\n",
    "    \"\"\"\n",
    "    Defects on the first move, then replicates the opponent's last move.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Defect' on the first move; then 'Cooperate' or 'Defect' based on the opponent's last action.\n",
    "    \"\"\"\n",
    "    if not opponent_history:\n",
    "        return 'Defect'\n",
    "    return opponent_history[-1]\n",
    "\n",
    "def random_strategy(_):\n",
    "    \"\"\"\n",
    "    A strategy that chooses randomly between cooperating and defecting.\n",
    "    \n",
    "    :return: Randomly 'Cooperate' or 'Defect'.\n",
    "    \"\"\"\n",
    "    return random.choice(['Cooperate', 'Defect'])\n",
    "\n",
    "def tester(opponent_history):\n",
    "    \"\"\"\n",
    "    Starts by cooperating, defects on the next turn, then mimics the opponent's last action if they defect.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Defect' if opponent defected last; otherwise, 'Cooperate'.\n",
    "    \"\"\"\n",
    "    if len(opponent_history) < 1:\n",
    "        return 'Cooperate'\n",
    "    if len(opponent_history) == 1:\n",
    "        return 'Defect'\n",
    "    return 'Cooperate' if opponent_history[-1] == 'Defect' else 'Defect'\n",
    "\n",
    "def gradual(opponent_history):\n",
    "    \"\"\"\n",
    "    Cooperates by default, but defects if the total number of defections by the opponent surpasses cooperations.\n",
    "    \n",
    "    :param opponent_history: List of the opponent's past actions.\n",
    "    :return: 'Defect' if defections > cooperations; otherwise, 'Cooperate'.\n",
    "    \"\"\"\n",
    "    defections = opponent_history.count('Defect')\n",
    "    if len(opponent_history) - defections < defections:\n",
    "        return 'Defect'\n",
    "    return 'Cooperate'\n",
    "\n",
    "\n",
    "def simulate_prisoners_dilemma(agent_a_strategy, iterations):\n",
    "    \"\"\"\n",
    "    Simulates the Prisoner's Dilemma game for a specified number of iterations using a strategy for Agent A.\n",
    "    \n",
    "    :param agent_a_strategy: A function representing the strategy Agent A will use.\n",
    "    :param iterations: The number of rounds the simulation will run.\n",
    "    :return: A tuple containing the results dictionary, scores of Agent A, scores of Agent B, and the agent instances.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the results dictionary to keep track of all possible game outcomes\n",
    "    results = {\"Cooperate-Cooperate\": 0, \"Cooperate-Defect\": 0, \"Defect-Cooperate\": 0, \"Defect-Defect\": 0}\n",
    "    \n",
    "    # Create instances of Agent A and B, passing the strategy function and the language model to Agent A\n",
    "    agent_a = Agent('Agent A', llm_api_key=api_key, strategy_func=agent_a_strategy)\n",
    "    agent_b = Agent('Agent B', llm_api_key=api_key)\n",
    "\n",
    "    # Lists to keep track of scores for both agents across iterations\n",
    "    scores_a, scores_b = [], []\n",
    "\n",
    "    # Simulate the game for the given number of iterations\n",
    "    for _ in range(iterations):\n",
    "        # Each agent decides on an action based on their strategy or language model\n",
    "        agent_a_choice = agent_a.decide_action()\n",
    "        agent_b_choice = agent_b.decide_action()\n",
    "\n",
    "        # Record the choices made by both agents in this round\n",
    "        round_result = {'Agent A': agent_a_choice, 'Agent B': agent_b_choice}\n",
    "        \n",
    "        # Update each agent's history with the outcome of the current round\n",
    "        agent_a.history.append(round_result)\n",
    "        agent_b.history.append(round_result)\n",
    "\n",
    "        # Update scores based on the actions taken by both agents\n",
    "        agent_a.update_score(agent_b_choice)\n",
    "        agent_b.update_score(agent_a_choice)\n",
    "\n",
    "        # Record the updated scores after each iteration\n",
    "        scores_a.append(agent_a.score)\n",
    "        scores_b.append(agent_b.score)\n",
    "\n",
    "        # Determine the outcome of the game based on the choices and update the results\n",
    "        game_outcome = f\"{agent_a_choice}-{agent_b_choice}\"\n",
    "        results[game_outcome] += 1\n",
    "\n",
    "        # Log the results of each iteration to a file for analysis\n",
    "        with open(\"strat_log.txt\", 'a') as log_file:\n",
    "            log_file.write(f\"{agent_a_strategy.__name__}, {_+1}, Agent A (Score:{agent_a.score}) chose {agent_a_choice}, Agent B (LLM) (Score:{agent_b.score}) chose {agent_b_choice} \\n\")\n",
    "\n",
    "        time.sleep(1.5)\n",
    "\n",
    "    # Return the simulation results, scores for both agents, and the agent instances\n",
    "    return results, scores_a, scores_b, agent_a, agent_b\n",
    "\n",
    "\n",
    "def describe_strategy(agent):\n",
    "    \"\"\"\n",
    "    Generates a description of the agent's strategy based on the game history using OpenAI's GPT.\n",
    "    \n",
    "    :param agent: The agent object whose strategy is to be described.\n",
    "    :return: A string description of the agent's strategy.\n",
    "    \"\"\"\n",
    "    # Construct the prompt using the agent's game history.\n",
    "    history_prompt = f\"Throughout the entire Prisoner's Dilemma game you are Agent B and your actions were as follows: {agent.history}. Based on this history, describe your strategy and decision-making process.\"\n",
    "    \n",
    "    # Initialize OpenAI with the API key.\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    try:\n",
    "        # Use the updated method for creating chat completions.\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a wise oracle. Please provide guidance.\"},\n",
    "                {\"role\": \"user\", \"content\": history_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract the decision from the response.\n",
    "        strategy_description = response['choices'][0]['message']['content'].strip()\n",
    "        return strategy_description\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"No response generated\"\n",
    "\n",
    "\n",
    "# Define the number of iterations for the game simulation and a list of strategies to be evaluated\n",
    "iterations = 200\n",
    "strategies = [tit_for_tat, tit_for_two_tats, generous_tit_for_tat, grim_trigger, pavlov, adaptive_strategy, suspicious_tit_for_tat, random_strategy, tester, gradual]\n",
    "\n",
    "# Check for the existence of summary files from previous simulations and delete them to start fresh\n",
    "if os.path.exists(\"strat_desc.txt\"):\n",
    "    os.remove(\"strat_desc.txt\")  # Remove the strategy description file if it exists\n",
    "\n",
    "if os.path.exists(\"strat_log.txt\"):\n",
    "    os.remove(\"strat_log.txt\")  # Remove the strategy log file if it exists\n",
    "\n",
    "if os.path.exists(\"llm_log.txt\"):\n",
    "    os.remove(\"llm_log.txt\")  # Remove the LLM log file if it exists\n",
    "\n",
    "if os.path.exists(\"strat_score.txt\"):\n",
    "    os.remove(\"strat_score.txt\")  # Remove the strategy score file if it exists\n",
    "\n",
    "# Write the header row outside of the loop to ensure it's only written once\n",
    "with open('strat_score.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Strategy Name', 'Agent A Score', 'Agent B (LLM) Score'])\n",
    "\n",
    "# Iterate over each strategy to simulate the Prisoner's Dilemma game and analyze the results\n",
    "for strategy in strategies:\n",
    "    # Simulate the game using the current strategy and collect results and scores\n",
    "    game_results, scores_a, scores_b, agent_a, agent_b = simulate_prisoners_dilemma(strategy, iterations)\n",
    "\n",
    "    # Plotting setup: initialize figure and plot scores over iterations for both agents\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, iterations + 1), scores_a, label='Agent A', color='blue')\n",
    "    plt.plot(range(1, iterations + 1), scores_b, label='Agent B', color='red')\n",
    "    plt.xlabel('Iteration')  # Label for the x-axis\n",
    "    plt.ylabel('Score')  # Label for the y-axis\n",
    "    # Set the title of the plot to include the name of the current strategy being evaluated\n",
    "    title = f\"Scores of Agent A and Agent B (LLM) over Iterations for {strategy.__name__}\"\n",
    "    plt.title(title)\n",
    "    plt.legend()  # Display a legend for the plot\n",
    "    plt.grid(True)  # Enable grid lines for better readability\n",
    "\n",
    "    # Define the filename for saving the plot based on the strategy name\n",
    "    image_file_name = f\"plot_{strategy.__name__}.png\"\n",
    "    plt.savefig(image_file_name)  # Save the plot as an image file\n",
    "\n",
    "    plt.show()  # Display the plot\n",
    "\n",
    "    # Request a description of Agent B's strategy from the language model\n",
    "    strategy_description_b = describe_strategy(agent_b)\n",
    "    print(f\"LLM strategy description:\\n{strategy_description_b}\\n\")  # Print the generated strategy description\n",
    "\n",
    "    # Append the strategy name and its description to the strategy description file\n",
    "    with open(\"strat_desc.txt\", 'a') as log_file:\n",
    "        log_file.write(f\"----------------------------------------------------------------------\\n\")\n",
    "        log_file.write(f\"\\nStrategy Name: {strategy.__name__}\\n\\n\")\n",
    "        log_file.write(f\"LLM strategy description:\\n{strategy_description_b}\\n\")\n",
    "\n",
    "    # Calculate the sum of scores for agents A and B for the current strategy\n",
    "    sum_scores_a = sum(scores_a)\n",
    "    sum_scores_b = sum(scores_b)\n",
    "\n",
    "    # Append the strategy scores to the CSV file\n",
    "    with open('strat_score.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([strategy.__name__, scores_a[-1], scores_b[-1]])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
